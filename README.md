# ğŸ Snake AI - Apprentissage par Renforcement

Un jeu de Snake classique avec une IA entraÃ®nÃ©e par apprentissage par renforcement profond (Deep Q-Learning).

## ğŸ“‹ Description

Ce projet implÃ©mente le jeu classique Snake avec deux modes :
- **Mode manuel** : jouable avec les touches directionnelles
- **Mode IA** : le serpent est contrÃ´lÃ© par un modÃ¨le de Deep Q-Learning

L'agent d'IA apprend Ã  jouer au Snake en maximisant les rÃ©compenses (manger de la nourriture) tout en Ã©vitant les obstacles (murs et son propre corps).

## ğŸš€ FonctionnalitÃ©s

- Interface graphique Pygame
- SystÃ¨me de score
- Agent DQN (Deep Q-Network) pour l'apprentissage par renforcement
- Visualisation de l'entraÃ®nement en temps rÃ©el avec graphiques
- Sauvegarde des meilleurs modÃ¨les

## ğŸ”§ Installation

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/votre-nom/snake-ai.git
cd snake-ai

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ“¦ DÃ©pendances

- Python 3.8+
- TensorFlow 2.x
- Pygame
- NumPy
- Matplotlib

## ğŸ’» Utilisation

### Jouer manuellement

```bash
python main.py
```

### EntraÃ®ner l'IA

```bash
python snake_train.py
```

### Tester l'IA entraÃ®nÃ©e

```bash
python snake_test.py
```

## ğŸ§  Architecture

- `main.py` : Point d'entrÃ©e principal
- `snake_logic.py` : Moteur du jeu Snake
- `snake_graphic.py` : Interface graphique Pygame
- `snake_dqn_agent.py` : Agent DQN pour l'apprentissage par renforcement
- `snake_train.py` : Script d'entraÃ®nement avec visualisation
- `snake_test.py` : Script de test pour l'agent entraÃ®nÃ©

## ğŸ”„ Processus d'apprentissage

L'agent apprend grÃ¢ce Ã  un rÃ©seau de neurones qui prÃ©dit les valeurs Q pour chaque action possible. Le processus comprend :

1. Observation de l'Ã©tat actuel (12 caractÃ©ristiques)
2. Choix d'une action (haut, droite, bas, gauche)
3. RÃ©ception d'une rÃ©compense (+100 pour manger, -100 pour mourir)
4. Mise Ã  jour du modÃ¨le via l'algorithme Q-learning

## ğŸ® ContrÃ´les

- **FlÃ¨ches directionnelles** : DÃ©placer le serpent
- **R** : Recommencer aprÃ¨s game over
- **Espace** : Pause (pendant l'entraÃ®nement)
- **Ã‰chap** : Quitter

## ğŸ“Š Performances

AprÃ¨s 1000 Ã©pisodes d'entraÃ®nement, l'agent atteint gÃ©nÃ©ralement un score moyen de 10-15, avec des pics Ã  25+.

## ğŸ› ï¸ AmÃ©liorations possibles

- ImplÃ©menter un algorithme PPO ou A3C
- Ajouter des obstacles dynamiques
- CrÃ©er diffÃ©rents niveaux de difficultÃ©
- Optimiser la reprÃ©sentation d'Ã©tat pour de meilleures performances

## Author

Doko

## ğŸ“œ Licence

MIT